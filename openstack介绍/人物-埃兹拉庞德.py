"""
美国诗人: 埃兹拉庞德

逻辑上存在:意思就是实际的真实情况下是不存在的,只是在人的意识形态中 假定存在. 比如说 神,鬼,上帝之类的东西,不是实际情况下真实的存在,只是
在人的意识里面虚构了这么一个东西,所以这样的就是逻辑上存在.

幂等的概念:
幂等这个概念，指重复操作不会产生任何影响。比如，电梯重复按两次，不会有差异。分布式系统特别强调幂等，因为通信可能丢失，就会需要重复发信号。


运输层:

1.>运输层为相互通信的应用进程提供逻辑通信.

从通信和信息处理的角度看,运输层向它上面的应用层提供通信服务,它属于面向通信部分的最高层,同时也是用户功能中的最底层.当网络的边缘部分中的两台主机使用网络的核心部分的功能进行端到端的通信时,


复用与分用概念:
	
	举个例子:假定一个机构的所有部门向外单位发出的公文都由收发室负责寄出,这相当于各部门都 复用 这个收发室.当收发室收到从外单位寄来的公文时,则要完成 分用 功能,即按照信封上的本机构的部门地址把公文正确地进行交付.


在这里再次体现了数据信息传递的渠道,方式体现.编程思想中也是这样的.要确定数据是从哪里获取,传递到哪里去(即存储到什么地方),数据的载体是什么,数据从一个地方到另外一个地方的过程中是不是需要加密(防止别人截获破解),数据到达指定位置后,进入目的地时的口令(类似通关文牒之类的验证身份的东西).这一切数据信息经历的过程都是根据这个社会的结构来设计的.所以不必觉得艰深晦涩,结合人自身所处的这个环境就能理解并运用了.


下面这些OSI七层之类的划分都是基于逻辑上的划分,并非在现实情况中真实存在的.
实际上,在一定程度看来,所有的实体概念之类的都是基于人的主观理解,主观逻辑进行划分的,那么从这个层次来想,个人主观的理解是存在差异的,因此,你可以认为苹果是水果,也可以认为苹果是蔬菜,是xxA,或者别的其他.只不过是在你的主观逻辑中进行这些品类划分的时候,人为的设置了划分标准.如果换另外一个人理解苹果,那可能是电子产品,或者服装,或者汽车,都是正常的,这些个人的理解都是基于这个人的思维结构和认知水平.并不存在谁对谁错的问题.只能说在一个群体中,谁更符合这个群体制定的思维模式,认知标准而已.所以,在共同协作开发的时候,才会制定那么多的文档设计标准,规范,要求,协议,API等等.有的时候其实你本不必赞同或者理解这些无关紧要的标准.你只需要会用就行.直接复制粘贴这些文档中的demo例子即可.具备独立思考能力的人往往在这个时候会很痛苦,因为你坚持认为自己的写法或做法是无比地正确,无比的牛叉.根本没有必要修改.其实没有必要纠结.因为最终的评判标准不是你个人的审美或者价值观.是制定标准/规范的那个人来评判.如果想通了这一点,那照章办事即可.


运输层的复用和分用:
	
	应用层所有的应用(就是一个qq音乐或者杀毒软件之类的桌面应用)进程都可以通过运输层(运输层就是收发室)再传送到IP(网络层),这就是复用.运输层从IP层收到发送给各应用进程的数据后,必须分别交付指明的各应用进程,这就是分用.显然,给应用层的每个应用进程赋予一个非诚明确的标志是至关重要的.


我们知道,在单个计算机中的进程是用进程标识符(一个不大的整数)来标志的.但是在互联网环境下,用计算机操作系统中所指派的这种进程标识符来标志运行在应用层的各种应用进程是不行的.这是因为在互联网上使用的计算机的操作系统种类很多,而不同的操作系统又实用不同格式的进程标识符.为了使用运行不同操作系统的计算机的应用进程能够互相通信,就必须使用统一的方法(而这种方法必须与特定操作系统无关)对TCP/IP体系的应用进程进行标志.

但是,把一个特定机器上运行的特定进程,指明为互联网上通信的最后重点还是不可行的.这是因为进程的创建和撤销都是动态的,通信的一方几乎无法识别对方机器上的进程.另外,我们往往需要利用目的主机提供的功能来识别终点.,而不需要知道具体实现这个功能的进程是哪一个(例如,要和互联网上的某个邮件服务器联系,并不一定要知道这个服务器功能是由目的主机上的哪个进程实现的).

解决这个问题的方法就是在运输层使用协议端口号.或通常简称为端口.这就是说,虽然通信的终点是应用进程,但只要把所传送的报文交到目的主机的某个合适的目的端口,剩下的工作(即最后交付目的进程)就由TCP和或UDP来完成.

请注意,这种在协议栈层间的抽象的协议端口是软件端口,和路由器或交换机上的硬件端口是完全不同的概念.硬件端口是不同硬件设备进行交互的接口,而软件端口是应用层的各种协议进程与运输实体进行层间交互的一种地址(类似寄信的时候,信封上面写的那种xx省xx市xx区xx小区xx单元xx号房间,本质是一个地址).不同的系统具体实现端口的方法可以是不同的(取决于系统使用的操作系统).


在UDP和TCP的首部格式中,它们都有源端口和目的端口这两个重要字段.
当运输层收到IP层交上来的运输层报文时,就能够根据其首部中的 目的端口号 把数据交付应用层的目的应用进程.

TCP/IP的运输层用一个16位端口号来标志一个端口.但请注意,端口号只具有本地意义,它只是为了标志本计算机应用层中的各个进程在和运输层交互时的层间接口.在互联网不同计算机中,相同的端口号是没有关联的.16位的端口号可允许有65535个不同的端口号,这个数目对一个计算机来说足够用的.

由此可见,两个计算机中的进程要互相通信,不仅必须知道对方的ip地址(为了找到对方的计算机),而且要知道对方的端口号(为了找到对方计算机中的应用进程)
.这和我们寄信的过程类似.当我们要给某人写信时,就必须在信封上的写明他的通信地址(这是为了找到他的住所,相当于ip地址),并且还要写上收件人的姓名(这是因为在同一住所中可能有好几个人,这相当于端口号.这个解释好.)在信封上还写明自己的地址.当收信人回信时,很容易在信封上找到发信人的地址.互联网上的计算机通信时采用客户-服务器方式.客户在发起通信请求时,必须先知道对方服务器的ip和端口号.因为运输层的短号号分为下面的两大类.

	1.>服务器端使用的端口号   这里又分为两类.最终要的一类叫作熟知端口号或系统端口号.数值为0~1023.(一听这个说法就是人为的划分的,只是逻辑上这么划分而已.)这些数值可在网址www.iana.org查到.IANA把这些端口号指派给的TCP/IP最重要的一些应用程序,让所有的用户都知道.当一种新的应用程序出现后,IANA必须为它指派一个熟知端口号.否则互联网上的其他应用进程就无法和它进行通信.
	另一类叫作登记端口号,数值为1024~49151.这类端口号是为没有熟知端口号的应用程序使用的.使用这类端口号必须在IANA按照规定的手续登记,以防止重复.

	2.>客户端使用的端口号   数值为49152~65536.由于这类端口号仅在客户进程运行时才动态选择,因此又叫做短暂短口号.这类端口号留给客户进程选择时暂时使用.当服务器进程收到客户进程的报文时,就知道了客户进程所使用的端口号,因而可以把数据发送给客户进程.通信结束后,刚才已使用过的客户端口号就不复存在,这个端口号就可以供其他客户进程使用.



关于进程:
	
	进程是一个动态的概念,比如,你启动qq,那么正在运行状态中的qq就是一个进程,如果你退出qq,那么刚刚正在运行的这个进程就消失了.所以,通俗的说法应该是:进程是正在运行中的应用程序.

关于发散:
	
	发散就是胡想.就是在一个指定的概念下开始进行关联想象,即使你想的是不对的,也没有关系,就是发散而已.比如,你看到苹果,想起甘肃,想起潘石屹,想起乔布斯,这些都是发散,都是正常的.没有正确与否.



关于位:
	只要文字描述中出现了 位 这个字眼,就是表示以二进制(0或1)表示的,16位端口号就是16个  0或1  的表示格式.没有其他特别的.




用户数据报协议UDP

1.>UDP概述

	用户数据报协议UDP只在IP的数据报服务之上增加了很少一点的功能,这就是复用和分用的功能以及差错检测的功能.UDP的主要特点是:
		1.>UDP是无连接的,即发送数据之前不需要建立连接(当然,发送数据结束时也没有连接可释放),因此减少开销发送数据之前的时延.
		2.>UDP使用尽最大努力交付,即不保证可靠交付,因此主机不需要维持复杂的连接状态表(这里面有许多参数).
		3.>UDP是面向报文的.发送方的UDP对应用程序交下来的报文,在添加首部后就向下交付IP层.UDP对应用层交下来的报文,既不合并,也不拆分,而是保留这些报文的边界.这就是说,应用层交给UDP多长的的报文,UDP就照样发送,即一次发送一个报文.因此,应用程序必须选择合适大小的报文,若报文太长,UDP把它交给IP层后,IP层在传送时可能要进行分片,这会降低IP层的效率.反之,若报文太短,UDP把它交给IP层后,会使IP数据报的首部的相对长度太大,这也降低了ip层的效率.
		4.>UDP没有拥塞控制,因此网络出现的拥塞不会使源主机的发送速率降低.这对某些实时应用是很重要的.很多的实时应用,(如IP电话,实时视频会议等)要求源主机以恒定的速率发送数据,并且允许在网络发生拥塞时丢失一些数据,但却不允许数据有太大的时延.UDP正好适合这种要求.
		5.>UDP支持一对一,一对多,多对一和多对多的交互通信.
		6.>UDP的首部开销小,只有8个字节,比TCP的20个字节的首部要短.

		虽然某些实时应用需要使用没有拥塞控制的UDP,但当很多的源主机同时都向网络发送高速率的实时视频流时,网络就有可能发生拥塞,结果大家都无法正常接收.因此,不使用拥塞控制功能的UDP有可能会引起网络产生严重的拥塞问题.
	

		还有一些使用UDP的实时应用,需要对UDP的不可靠的传输进行适当的改进,以减少数据的丢失.在这种情况下,应用进程本身可以在不影响应用的实时性的前提下,增加一些提高可靠性的措施,如采用前向纠错或重传已丢失的报文.


传输控制协议TCP概述
	
	TCP最主要的特点:
		TCP是TCP/IP体系中非常复杂的一个协议.
		特点:
		1.>TCP是面向连接的运输层协议.这就是说,应用程序在使用TCP协议之前,必须先建立TCP连接.在传送数据完毕后,必须释放已经建立的TCP连接.也就是说,应用进程之间的通信好像在"打电话":通话前要先拨号建立连接,通话结束后要挂机释放连接.
		2.>每一条TCP连接只能有两个端点,每一条TCP连接只能是点对点的(一对一).
		3.>TCP提供可靠交付的服务.通过TCP连接传送的数据,无差错,不丢失,不重复,并且按需到达.
		4.>TCP提供全双工通信.TCP允许通信双方的应用进程在任何时候都能发送数据.TCP连接的两端都设置有发送缓存和接收缓存,用来临时存放双向通信的数据.在发送时,应用程序在把数据传送给TCP的缓存后 ,就可以做自己的事,而TCP在合适的时候把数据发送出去.在接收时,TCP把收到的数据放入缓存.上层的应用进程在合适的时候读取缓存中的数据.
		5.>面向字节流.TCP中的流(stream)指的是流入进程或从进程流出的字节序列."面向字节流"的含义是:虽然应用程序和TCP的交互时一次一个数据块(大小不等),但TCP把应用程序交下来的数据仅仅看成是一连串无结构的字节流.TCP并不知道所传送的字节流的含义.TCP不保证接收方应用程序所收到的数据块和发送方应用程序所发出的数据块具有对应大小的关系.(例如,发送方应用程序交给发送方的TCP共10个数据块,但接收方的TCP可能只用了4个数据块就把收到的字节流交付上层的应用程序).但接收方应用程序收到的字节流必须和发送方应用程序发出的字节流完全一样.当然,接收方的应用程序必须有能力识别收到的字节流,把它还原成有意义的应用层数据.

	图中的TCP连接是一条虚连接(也就是逻辑连接),而不是一条真正的物理连接.TCP报文段先要传送到IP层,加上IP首部后,再传送到数据链路层.再加上数据链路层的首部和尾部后,才离开主机发送到物理链路.

	TCP和UDP在发送报文时所采用的方式完全不同.TCP并不关心应用进程一次把多长的报文发送到TCP的缓存中,而是根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应该包含多少个字节(UDP发送的报文长度是应用进程给出的).如果应用进程传送到TCP的缓存的数据块太长,TCP就可以把它划分短一些再传送.如果应用进程一次只发送来一个字节,TCP也可以等到积累有足够多的字节后再构成报文段发送出去.


TCP的连接

	TCP把连接作为最基本的抽象.TCP的许多特性都与TCP是面向连接的这个基本特性有关.
	每一条TCP连接都有两个端点.那么,TCP连接的端点是什么呢?不是主机,不是主机的IP的地址,不是应用进程,也不是运输层的协议端口.TCP连接的端点叫作套接字或插口.根据RFC793的定义:端口号拼接到IP地址即构成了套接字.因此,套接字的表示方法是在点分十进制的IP地址后面写上端口号,中间用冒号或逗号隔开.例如,若IP地址是192.3.4.5而端口号是80,那么得到的套接字就是192.3.4.5:80,总之,我们有 套接字socket = (IP地址:端口号)

	每一条TCP连接唯一地被通信两端的两个端点(即两个套接字)所确定.即:

		TCP连接 ::= {socket1,socket2} = {(IP1,port1),(IP2,port2)}

	这里IP1和IP2分别是两个端点主机的IP地址,而port1和port2分别是两个端点主机中的端口号.TCP连接的两个套接字就是socket1和socket2.可见套接字socket是个很抽象的概念.

	总之,TCP连接就是由协议软件所提供的一种抽象.虽然有时为了方便,我们也可以说,在一个应用进程和另外一个应用进程之间建立了一条TCP连接,但一定要记住:TCP连接的端点是个很抽象的套接字,即(IP地址:端口号).也还应记住:同一个IP地址可以有多个不同的TCP连接,而同一个端口号也可以出现在多个不同的TCP连接中.

	请注意,socket这个名词有时容易使人把一些概念混淆,因为随着互联网的不断发展以及网络技术的进步,同一个名词socket却可以表示多种不同的意思.例如:

		1.>允许应用程序访问联网协议的 应用编程接口API,即运输层和应用层之间的一种接口,称为socketAPI,并简称为socket
		2.>在socketAPI中使用的一个函数名也叫作socket.
		3.>调用socket函数的端点称为socket,如"创建一个数据报socket"
		4.>调用socket函数时,其返回值称为socket描述符,可简称为socket.
		5.>在操作系统内核中联网协议的Berkeley实现,称为socket实现.

		这些概念中提到的socket和这里提到的socket(指端口号拼接到IP地址不同)


可靠传输的工作原理:
	
	我们知道,TCP发送的报文段是交给IP层传送的.但IP层只能提供尽最大努力服务,也就是说,TCP下面的网络所提供的的是不可靠的传输.因此,TCP必须采用适当的措施才能使得两个运输层之间的通信变得可靠.
	理想的传输条件有以下两个特点:

		1.>传输信道不产生差错.
		2.>不管发送方以多快的速度发送数据,接收方总是来得及处理收到的数据.
		在这样的理想传输条件下,不需要采用任何措施就能够实现可靠传输.
		然而实际的网络都不具备以上两个理想条件.但我们可以使用一些可靠传输协议.当出现差错时让发送方重传出现差错的的数据,同时在接收方来不及处理收到的数据时,及时告诉发送方适当降低发送数据的速度.这样一来,本来不可靠的传输信道就能实现可靠传输了.

	1.>停止等待协议

		全双工通信的双方既是发送方也是接收方. 这里是讨论可靠传输的原理,因此把传送的数据单元都称为分组.而并不考虑数据是在哪一个层次上传送的."停止等待"就是每发送完一个分组就停止发送,等待对方的确认.在收到确认后再发送下一个分组.

			1.>无差错的情况

				停止等待协议:
					可靠传输协议是这样设计的:A只要超过了一段时间仍然没有收到确认,就认为刚才发送的分组丢失了,因而重传前面发送过的分组.这就叫做超时重传.要实现超时重传,就要在每发送完一个分组时设置一个超时计时器.如果在超时计时器到期之前收到了对方的确认,就撤销已设置的超时计时器.

				这里应注意以下三点:
					第一,A在发送完一个分组后,必须暂时保留已发送的分组的副本(在发生超时重传时使用).只有在收到相应的确认后才能清除暂时保留的分组副本.
					第二,分组和确认分组都必须进行编号.这样才能明确是哪一个发送出去的分组收到了确认,而哪一个分组还没有收到确认.
					第三,超时计时器设置的重传时间应当比数据在分组传输的平均往返时间更长一些.显然,如果重传时间设定得很长,那么通信的效率就会很低,但如果重传的时间设定的太短,以致产生不必要的重传,就浪费了网络资源.然而,在运输层重传时间的准确设定是非常复杂的,这是因为已发送出的分组到底会经过哪些网络,以及这些网络将会产生多大的时延(这取决于这些网络当时的拥塞情况),这些都是不确定因素.


		自动重传请求ARQ(Automatic Repeat reQuest)意思是重传的请求时自动进行的.接收方不需要请求发送方重传某个出错的分组.

			
抽象:就是假的.没有实际的真实的存在.只是人的思维体现.


5.5  TCP报文段的首部格式:

	TCP虽然是面向字节流的,但TCP传送的数据单元却是报文段.一个TCP报文段分为首部和数据两部分,而TCP的全部功能都体现在它首部中各字段的作用.因此,只有弄清TCP首部各字段的作用才能掌握TCP的工作原理.

	TCP首部的最小长度是20字节.




TCP的拥塞机制:

	在计算机网络中的链路容量(即带宽),交换结点中的缓存和处理机等,都是网络的资源.在某段时间,若对网络中某一资源的需求超过了该资源所能提供的可用部分,网络的性能就要变坏.这种情况就叫做拥塞.可以把出现网络拥塞的条件写成如下的关系式: 对资源的需求 求和 > 可用资源.

	网络拥塞往往是由许多因素引起的.例如,当某个结点缓存的容量太小时,到达该结点的分组因无存储空间暂存而不得不被丢弃.现在设想将该结点缓存的容量扩展到非常大,于是到达该结点的分组均可在结点的缓存队列中排队,不受任何限制.由于输出链路的容量和处理机的速度并未提高,因此在这队列中的绝大多数分组的排队等待时间将会大大增加,结果上层软件只好把它们进行重传(因为早就过时了),由此可见,简单地扩大缓存的存储空间同样会造成网络资源的严重浪费,因而解决不了网络拥塞的问题.

	又如,处理机处理的速率太慢可能引起网络的拥塞.简单地将处理机的速率提高,可能会使上述情况缓解一些,但往往又会将瓶颈转移到其他地方.问题的实质往往是整个系统的各个部分不匹配,只有所有的部分都平衡了,问题才会得到解决.

	拥塞控制与流量控制的关系密切,它们之间也存在一些差别.所谓拥塞控制就是防止过多的数据注入到网络中,这样可以使网络中的路由器或链路不至过载.拥塞控制所要做的都有一个前提,就是网络能够承受现有的网络负荷.拥塞控制是一个全局性的过程.涉及到所有的主机,所有的路由器,以及与降低网络传输性能有关的所有因素.但TCP连接的端点只要迟迟不能收到对方的确认信息.就猜想在当前网络中的某处很可能发生了拥塞,但这是却无法知道拥塞到底发生在网络的何处?还是在某个地区出现自然灾害?

	相反,流量控制往往是指点对点通信量的控制,是个端到端的问题(接收端控制发送端)流量控制所要做的就是抑制发送端发送数据的速率,以便接收端来得及接收.

	
	拥塞控制和流量控制之所以常常被弄混,是因为某些拥塞控制算法是向发送端发送控制报文,并告诉发送端,网络已出现麻烦,必须放慢发送速率.这点又和流量控制是很相似的.

	进行拥塞控制需要付出的代价.这首先需要获得网络内部流量分布的信息.在实施拥塞控制时,还需要在结点之间交换信息和各种命令,以便选择控制的策略和实施机制.这样就产生了额外开销.拥塞控制有时需要将一些资源(如缓存,带宽等)分配给个别用户(或一些类别的用于)


红黑树:
	

开环控制:开环控制就是在设计网络时事先将有关发生拥塞的因素考虑到,力求网络在工作时不产生拥塞.但一旦整个系统运行起来,就不再中途进行改正了.
	
	闭环控制是基于反馈环路的概念,主要有以下几种措施:
	1.>监测网络系统以便检测到拥塞在何时,何处发生.
	2.>把拥塞发生的信息传送到可采取行动的地方.
	3.>调整网络系统的运行以解决出现的问题.


TCP的拥塞控制方法

	TCP进行拥塞控制的算法有四种,即慢开始,拥塞避免,快重传和快恢复.

	发送方控制拥塞控制也叫做基于窗口的拥塞控制.为此,发送方维持一个叫做拥塞窗口的状态变量.拥塞窗口的大小取决于网络的拥塞程度,并且动态地在变化.发送方让着自己的发送窗口等于拥塞窗口.

	发送方控制拥塞窗口的原则是:只要网络没有出现拥塞,拥塞窗口就可以再增大一些,以便把更多的分组发出去,这样就可以提高网络的利用率.但只要网络出现拥塞或有可能出现拥塞,就必须把拥塞窗口减小一些,以减少注入到网络中的分组数,以便缓解网络出现的拥塞.

	发送方又是如何知道网络发生了拥塞呢?我们知道,当网络发生拥塞时,路由器就要丢弃分组.因此只要发送方没有按时收到应当到达的确认报文,也就是说,只要出现了超时,就可以猜想网络可能出现了拥塞.现在通信线路的传输之类一般都很好,因传输出差错而丢弃分组的概率是很小的.因此,判断网络拥塞的依据就是出现了超时.

	"慢开始算法":慢开始算法的思路是这样的:当主机开始发送数据时,由于并不清楚网络的负荷情况,所以如果立即把大量数据字节注入到网络,那么就有可能引起网络发生拥塞.经验证明,较好的方法是先探测一下,即由小到大逐渐增大发送窗口,也就是说,由小到大逐渐增大拥塞窗口数值.

	慢开始规定,在每收到一个对新的报文段的确认后,可以把拥塞窗口增加最多一个SMSS的数值.
	
	采用快重传算法可以让发送方尽早知道发生了个别报文段的丢失.快重传算法首先要求接收方不要等待自己发送数据时才进行捎带确认,而是要立即发送确认,即使收到了失序的报文段也要立即发出对已收到的报文段的重复确认.
	
	快重传算法规定,发送方只要一连收到3个重复确认,就知道接收方确实没有收到报文段M3因而应当立即进行重传(即快重传).这样就不会出现超时,发送方也就不会误认为出现了网络拥塞.使用快重传可以使整个网络的吞吐量提高约20%.

	主动队列管理AQM:

		例如,假定一个路由器对某些分组的处理时间特别长,那么这就可能使这些分组中的数据部分(即TCP报文段)经过很长时间才能到达终点,结果引起发送方对这些报文段的重传.根据前面所讲的,重传会使TCP连接的发送端认为在网络中发生了拥塞.于是在TCP的发送端就采取了拥塞控制措施,但实际上网络并没有发生拥塞.

		网络层的策略对TCP控制影响最大的就是路由器的分组丢弃策略.在最简单的情况下,路由器的队列通常都是按照"先进先出"的规则处理到来的分组.由于队列长度总是有限的,因此当队列已满时,以后再到达的所有分组(如果能够继续排队,这些分组都将排在队列的尾部)将都被丢弃.这就叫做尾部丢弃策略.

		路由器的尾部丢弃往往会导致一连串分组的丢失,这就使发送方出现超时重传,使TCP进入拥塞控制的慢开始状态,结果使TCP连接的发送方突然把数据的发送速率降低到很小的数值.更为严重的是,在网络中通常有很多的TCP连接(它们有不同的源点和终点),这些连接中的报文段通常是复用在网络层的IP数据报中传送.在这种情况下,若发生了路由器中的尾部丢弃,就可能会同时影响到很多条TCP连接,结果使这许多TCP连接在同一时间突然都进入到慢开始的状态.这在TCP的术语中称为全局同步.全局同步使得全网的通信量突然下降了很多,而在网络恢复正常后,其通信量又突然增大很多.


		为了避免发生网络中的全局同步现象,在1998年提出了主动队列管理AQM.所谓主动就是不要等到路由器的队列长度已经达到最大值时才不得不丢弃后面到达的分组.这样就太被动了.应当在队列长度达到某个值得警惕的数值时(即当网络拥塞有了某些拥塞征兆时),就主动丢弃到达的分组.这样就提醒了发送方放慢发送的速率,因而有可能使网络拥塞的程度减轻,甚至不出现网络拥塞.AQM可以有不同实现方法,其中曾留下性多年的就是随机早期检测RED.RED还有几个不同的名称,如随机早期丢弃.

		实现RED时需要使路由器维持两个参数,即队列长度最小门限和最大门限.当每一个分组到达时,RED就按照规定的算法先计算当前的平均队列长度.

			1.>若平均队列长度小于最小门限,则把新到达的分组放入队列进行排队.
			2.>若平均队列长度超过最大门限,则把新到达的分组丢弃.
			3.>若平均队列长度在最小门限和最大门限之间,则按照某一丢弃概率p把新到达的分组丢弃(这就体现了丢弃分组的随机性)

		在RED的操作中,最难处理的就是丢弃概率p的选择,因为p并不是个常数.对每一个到达的分组,都必须计算丢弃概率p的数值.IETF曾经推荐在互联网中的路由器使用RED机制.


优秀的项目地址:
https://github.com/kon9chunkit/GitHub-Chinese-Top-Charts?utm_source=gold_browser_extension













































"""