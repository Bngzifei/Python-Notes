# 高性能的负载均衡

## 1、HTTP负载均衡

### 问题：

将用户请求分发到 2 台以上 HTTP 服务器。 

### 解决方案： 

使用 NGINX 的 HTTP 模块，将请求分发到有 upstream 块级指令代理的 HTTP服务器集群，实现负载均衡：

```
upstream backend { server 10.10.12.45:80 weight=1; server app.example.com:80 weight=2; }
server { location / { proxy_pass http://backend; } }
```

配置中启用了两台默认 80 端口 HTTP 服务器构成服务器集群。weight 参数表示 

没三个请求将有 2 个请求分发到 app.example.com:80 服务器，它的默认值为 1。 

### 结论:

HTTP 模块的 upstream 用于设置被代理的 HTTP 服务器实现负载均衡。模块 

内定义一个目标服务器连接池，它可以是 UNIX 套接字、IP 地址、DNS 记录 

或它们的混合使用配置；此外 upstream 还可以通过 weight 参数配置，如何 

分发请求到应用服务器。 

所有 HTTP 服务器在 upstream 块级指令中由 server 指令配置完成。server 

指令接收 UNIX 套接字、IP 地址或 FQDN(Fully Qualified Domain Name: 全限 

定域名) 及一些可选参数。可选参数能够精细化控制请求分发。它们包括用于负 

载均衡算法的 weight 参数；判断目标服务器是否可用，及如何判断服务器可用 

性的 max_fails 指令和 fail_timeout 指令。NGINX Plus 版本提供了许多其他 

方便的参数，比如服务器的连接限制、高级DNS解析控制，以及在服务器启动后 

缓慢地连接到服务器的能力。 



## 2、TCP负载均衡配置

### 问题:

将请求分发到 2 台以上 TCP 服务器。

### 解决方案:

在 NGINX 的 stream 模块内使用 upstream 块级指令实现多台 TCP 服务器负载 

均衡：

```nginx
stream { 
    upstream mysql_read { 
        server read1.example.com:3306 weight=5; server read2.example.com:3306; server 10.10.12.34:3306 backup; 
    }
server { 
        listen 3306; proxy_pass mysql_read; 
    } 
}
```

例中的 server 块级指令指定 NGINX 监听 3306 端口的多台 MySQL 数据库 

实现负载均衡，其中 10.10.12.34:3306 作为备用数据库服务器当负载请 

求分发失败时会被启用。

### 结论:

TCP 负载均衡在 stream 模块中配置实现。stream 模块类似于 http 模块。 

配置时需要在 server 块中使用 listen 指令配置待监听端口或 IP 加端口。 

接着，需要明确配置目标服务，目标服务可以使代理服务或 upstream 指令 

所配置的连接池。 TCP 负载均衡实现中的 upstream 指令配置和 HTTP 负载 

均衡实现中的 upstream 指令配置相似。TCP 服务器在 server 指令中配置， 

格式同样为 UNIX 套接字、IP地址或 FQDN(Fully Qualified Domain Name: 

全限定域名)；用于精细化控制的 weight 权重参数、最大连接数、DNS 解析 

器、判断服务是否可用和启用为备选服务的 backup 参数一样能在 TCP 负载 

均衡中使用。

## 3、负载均衡算法

### 问题:

对于负载压力不均匀的应用服务器或服务器连接池，轮询(round-robin)负载均衡算法 

无法满足业务需求。

### 解决方案:

使用 NGINX 提供的其它负载均衡算法，如：最少连接数(least connections)、 

最短响应时间(leaest time)、通用散列算法(generic hash)或 IP 散列算法(IP hash)： 

```nginx
upstream backend { least_conn; server backend.example.com; server backend1.example.com; }
```

上面的 least_conn 指令为 upstream 所负载的后端服务，指定采用最少连接数 

负载均衡算法实现负载均衡。所有的负载均衡算法指令，除了通用算列指令外， 

都和上面示例一样是一个普通指令，需要独占一行配置。通用散列指令，接收一个 

参数，也可以使一系列变量值的拼接结果，来构建散列值。 

### 结论:

在负载均衡中，并非所有的请求和数据包请求都具有相同的权重。有鉴于此， 

如上例所示的轮询或带有权重的轮询负载均衡算法，可能并不能满足我们的 

应用或负载需求。NGINX 提供了一系列的负载均衡算法，以满足不同的运用 

场景。所有提供的负载均衡算法都可以针对业务场景随意选择和配置，并且 

都可以应用于 upstream 块级指令中的 HTTP、TCP 和 UDP 负载均衡服务器 

连接池。

### 轮询负载均衡算法(**Round robin**)

NGINX 服务器默认的负载均衡算法，该算法将请求分发到 upstream 指令块 

中配置的应用服务器列表中的任意一个服务器。可以通过应用服务器的负载 

能力，为应用服务器指定不同的分发权重(weight)。权重的值设置的越大，将 

被分发更多的请求访问。权重算法的核心技术是，依据访问权重求均值进行 

概率统计。轮询作为默认的负载均衡算法，将在没有指定明确的负载均衡指令 

的情况下启用。 

### 最少连接数负载均衡算法(**Least connections**)

NGINX 服务器提供的另一个负载均衡算法。它会将访问请求分发到upstream 所代理的

应用服务器中，当前打开连接数最少的应用服务器实现负载均衡。最少连接数负载均衡，

提供类似轮询的权重选项，来决定给性能更好的应用服务器分配更多的访问请求。

该指令的指令名称是least_conn。 

### 最短响应时间负载均衡算法(**least time**)

该算法仅在 NGINX PLUS 版本中提供，和最少连接数算法类似，它将请求 

分发给平均响应时间更短的应用服务器。它是负载均衡算法最复杂的算法 

之一，能够适用于需要高性能的 Web 服务器负载均衡的业务场景。该算法 

是对最少连接数负载均衡算法的优化实现，因为最少的访问连接并非意味着 

更快的响应。该指令的配置名称是 least_time。 

### 通用散列负载均衡算法(**Generic hash**)

服务器管理员依据请求或运行时提供的文本、变量或文本和变量的组合 

来生成散列值。通过生成的散列值决定使用哪一台被代理的应用服务器，并 

将请求分发给它。在需要对访问请求进行负载可控，或将访问请求负载到 

已经有数据缓存的应用服务器的业务场景下，该算法会非常有用。需要注意 

的是，在 upstream 中有应用服务器被加入或删除时，会重新计算散列进行 

分发，因而，该指令提供了一个可选的参数选项来保持散列一致性，减少 

因应用服务器变更带来的负载压力。该指令的配置名称是 hash。 

### IP 散列负载均衡算法(IP hash)

该算法仅支持 HTTP 协议，它通过计算客户端的 IP 地址来生成散列值。 

不同于采用请求变量的通用散列算法，IP 散列算法通过计算 IPv4 的前 

三个八进制位或整个 IPv6 地址来生成散列值。这对需要存储使用会话， 

而又没有使用共享内存存储会话的应用服务来说，能够保证同一个客户端 

请求，在应用服务可用的情况下，永远被负载到同一台应用服务器上。 

该指令同样提供了权重参数选项。该指令的配置名称是 ip_hash。



#  服务器健康监控

访问应用时，可能由于网络连接失败，Web 服务器宕机或应用程序异常等原因导致 

应用程序无法访问。这时，代理或负载均衡器需要提供能够智能检测被代理或被负 

载的 Web 服务是否无法访问的能力，来确保不会请求分发到这些失效的服务器。 

同时，客户端会收到连接超时的响应，结束请求等待状态。 

通过代理服务器向被代理服务器发送健康检测请求，来判断被代理服务器是否失效，是

一种减轻被代理服务器压力的有效方法。NGINX 服务器提供两种不同的健康检测方案： 

被动检测和主动检测，开源版的 NGINX 提供被动检测功能， NGINX PLUS 提供主动检 

测功能。主动检测的实现原理是，NGINX 代理服务向被代理服务器定时的发送连接请求， 

如果被代理服务器正常响应，则说明被代理服务器正常运行。被动检测的实现原理是： 

NGINX 服务器通过检测客户端发送的请求及被代理(被负载均衡)服务器的响应结果进行 

判断被代理服务器是否失效。被动检测方案，可以有效降低被代理服务器的负载压力； 

主动检测则能够在客户端发送请求之前，就能够剔除掉失效服务器。 

## 1、健康监控内容

### 问题:

你想对服务器进行有效检测，但不止如何去检测服务器健康状况。 

### 解决方案:

使用一个简单粗暴的检测方案实现应用健康检测。如，负载均衡器通过获取被负载 

服务器的响应状态码是否为 200 判断应用服务器进程是否正常。

### 结论:

实际项目中，对被负载的提供核心功能的应用服务器进行健康检测非常重要。 

仅仅通过一种健康检测方案，确保核心服务是否可用，通常并不完全可靠。 

健康检测应该通过网络直接检测被负载的应用服务器和应用本身是否运行正常， 

来确保服务可用，这比仅使用负载均衡器来检测服务是否可用要可靠。 

一般，可以选择一个功能来进行健康检测，来确保整个服务是否可用。比如， 

确认数据库连接是否正常或应用是否能够正常获取它的资源。任何一个服务失效， 

都可能引发蝴蝶效应导致整个服务不可用。

## 2、TCP服务器监控检测

### 问题:

需要检测 TCP 服务器是否正常并从代理池中移除失效服务器。

### 解决方案:

在 server 块级指令中 使用 health_check 简单指令，对被代理服务器进行 

健康检测: 

```
stream { server { listen 3306; proxy_pass read_backend; health_check interval=10 passes=2 fails=3; } }
```

上面的配置会对代理池中的服务器进行主动监测。如果被代理服务器未能正常 

响应 NGINX 服务器的 3 个以上 TCP 连接请求，则被认为是失效的服务。 

之后，NGINX 服务器会每隔 10 秒进行一次健康检测。

### 结论:

在 NGINX PLUS 版本中同时提供被动检测和主动检测功能。被动检测是通过加之于 

客户端与被代理服务器的请求响应检测实现的。如果一个请求超时或者连接失败， 

被动检测则认为该被代理服务器失效。主动检测则是通过明确的 NGINX 指令配置 

来检测服务器是否失效。主动检测途径可以是一个测试的连接，也可以是一个预期 

的响应。 

## 3、HTTP服务器监控检测

### 问题:

需要主动检测 HTTP 服务器健康状态 

### 解决方案:

在 location 块级指令中使用 health_check 指令检测：

```nginx
http {server { ... location / { proxy_pass http://backend; health_check interval=2s fails=2 passes=5 uri=/ match=welcome; } }# status is 200, content type is "text/html", # and body contains "Welcome to nginx!" match welcome { status 200; header Content-Type = text/html; body ~ "Welcome to nginx!"; } }
```

上例，通过向被代理服务器每隔 2 秒，发送一个到 '/' URI 的请求来检测 

被代理服务器是否失效。被代理服务器连续接收 5 个请求，如果其中有 2 个 

连续请求响应失败，将被视作服务器失效。被代理服务器的健康响应格式 

在 match 块级指令中配置，规定响应状态码为 200, 响应 Content-Type类型为 

'text/html',响应 body 为 "Welcome to nginx!" 字符串的响应为有效服务器。

### 结论:

在 NGINX PLUS 版本中，除了通过响应状态码来判断被代理服务器是否有效。 

还能够通过其它的一些响应指标来判断是否有效。如：主动检测的时间间隔 

(频率)，主动请求的 URI 地址，健康检测的请求次数及失败次数和预期响应 

结果等。在 health_check 指令中的 match 参数指向 match 块级指令配置， 

match 块级指令配置定义了标准的响应，包括 status、header 和 body 指令， 

他们都有各自的检测标准。

# 大规模可伸缩缓存配置

通过对请求的响应结果进行缓存，能够为后续相同请求提供加速服务。对相同请求 

响应内容进行内容缓存(Content Caching)，相比每次请求都重新计算和查询被代理 

服务器，能有效降低被代理服务器负载。内容缓存能提升服务性能，降低服务器负 

载压力，同时意味着能够使用更少的资源提供更快的服务。可伸缩的缓存服务从架构 

层面来讲，能够显著提升用户体验，因为响应内容经过更少的转发就能够发送给用户， 

同时能提升服务器性能。 

## 1、缓存区域配置

### 问题：

需要定义响应内容的缓存路径及缓存操作

### 解决方案:

使用 proxy_cache_path 指令为待缓存定义内容缓存区域的共享内存及缓存路径：

```nginx
proxy_cache_path /var/nginx/cache
 keys_zone=CACHE:60m
 levels=1:2
 inactive=3h
 max_size=20g;
proxy_cache CACHE;
```

上面的配置中在 proxy_cache_path 指令中为响应在文件系统中定义了缓存的存 

储目录 /var/nginx/cache，并使用 keys_zone 参数创建名为 CACHE 的拥有 

60 M 的缓存内存空间；同时通过 levels 参数定义目录解构级别，通过 inactive 

参数指明如果相同请求的缓存在 3 小时内未被再次访问则被释放，并使用 max_size 

定义了缓存最大可用存储空间为 20 G。

###  结论:

要使用 NGINX 内容缓存，需要在配置中定义缓存目录及缓存区域(zone)。 

通过 proxy_cache_path 指令创建 NGINX 内容缓存，定义用于缓存信息的路 

径和用于存储缓存的元数据(metadata)和运行时键名(active keys)的共享内存。 

其它的可选参数，还提供缓存如何维护和访问的控制，levels 参数定义如何 

创建文件结构，定义子目录的文件名长度，语法是以冒号分隔的值，支持最大 

3 级。

NGINX 的所有缓存依赖于最终被计算成散列的 cache key，接着将结果以 

cache key 作为文件名，依据缓存级别创建缓存目录。 

inactive 参数用于控制最后一次使用缓存选项的时间，超过这个时间的缓存 

会被释放。缓存的大小则可以通过 max_size 参数进行配置。还有部分参数 

作用于缓存加载进程中，功能是将 cache keys 从磁盘文件加载仅共享内存里。

## 2、配置缓存哈希键名

### 问题:

自定义如何缓存和查找缓存内容

### 解决方案:

通过一条单独的 proxy_cache_key 指令，以变量名的形式定义缓存命中和 

丢弃的规则。 

```
proxy_cache_key "$host$request_uri $cookie_user";
```

上例指令依据请求域名、请求 URI 和用户 cookie 作为缓存 

键名，来构建 NGINX 的缓存页面。这样，就可以对动态页面进行缓存，而 

无需对每个用户都进行缓存内容的生成处理。

### 结论:

proxy_cache_key 默认设置是 "$scheme$proxy_host $request_uri"。默认设置 

适用于多数的使用场景。配置之中包括 scheme、HTTP 或 HTTPS、代理域名 

(proxy_host)、请求的 URI 等变量。总之，它们能够正确处理 NGINX 代理请求。

您可能会发现，对于每个应用程序，有许多其他的因素可以定义一个惟一的请求， 

比如请求参数、头文件、会话标识符等等，您需要创建自己的散列键。或许你 

已经发现，对一个应用，还有其它的数据能够确定一个唯一的请求，比如请求参数、 

请求头(headers)、会话标识(session identifiers) 等等，这些都可以用于 

构建自己的散列键名。在构建时应基于应用程序的理解，创建选择一个好的散列 

键名，这一点非常重要。比较简单的是为静态内容创建缓存键名，通常，可以直接 

使用域名(hostname)和请求 URI 就可以了。而类似于仪表盘这类的，具有动态内 

容的页面，则需要充分了解用户和应用之间的交互、以及用户体验之间的差异，来 

构建缓存键名。如从安全的角度触发，你可能不希望缓存将一个用户的缓存数据展

示给另外的用户。proxy_cache_key 令配置了用于缓存生成哈希值字符，此条指令 

可以在 HTTP、server、location 块级指令上下文中定义，实现对请求如何缓存的 

灵活控制。

## 3、跳过被缓存内容

### 问题:

将一些内容不进行缓存 

### 解决方案:

将 proxy_cache_passby 指令，设置称非空值或非 0。一种途径是，在 location 

块级指令中设置一个值等于 1 的 proxy_cache_passby 指令： 

```
proxy_cache_bypass $http_cache_bypass;
```

配置告知 NGINX 服务器，如果一个 HTTP cache_passby 请求头的值设置为非 

0(或非空)，则不对该请求进行缓存处理。

### 结论:

挺多应用场景下都不应对请求进行缓存处理，对此，NGINX 提供 proxy_cache_passby 

指令来应对这些场景。通过将指令值设置为非空或非零，匹配的请求 URI 会直接发送给 

被代理服务器，而不是从缓存中获取。如何使用该指令，需要结合客户端和应用的实际 

使用。它既可以配制成如同一个请求变量一样简单，也可以配置成复杂的映射指令块。 

但最终目的都是绕过缓存。其中，一个重要的应用场景就是排除故障和调试应用。如果 

在研发过程中一直使用缓存，或对特定用户进行缓存，缓存会影响问题的复现。提供对指定 

cookie、请求头(headers)或请求参数等的缓存绕过能力，则是一个必要的功能。此外， 

NGINX 服务器还能够在 location 块指令中将 proxy_cache 指令设置为 off，完全禁用 

缓存。

## 4、缓存性能

### 问题:

需要在客户端提升服务性能 

### 解决方案:

使用客户端缓存控制消息头： 

```
location ~* \.(css|js)$ {
 expires 1y;
 add_header Cache-Control "public"; }
```

该 location 块指令设置成功后，客户端可以对 CSS 和 JS 文件进行缓存。expires 

指令将所有缓存的有效期设置为 1 年。add_header 指令将 HTTP 消息头 Cache-Control 

设置成 public 并加入响应中，表示所有的缓存服务器都可以缓存资源。如果将它的值 

设置为 private，则表示仅允许客户端对资源进行缓存。 

### 结论:

缓存的性能和许多因素有关，其中磁盘读写速度是影响缓存性能的重要原因之一。 

在 NGINX 配置指令中，还有很多能够提升性能的指令。像上例中配置的，通过 

设置 Cache-Control 响应消息头，客户端会直接从本地读取缓存，而不会将请求 

发送给服务器来提升性能。 

# UDP负载均衡

## 1、Stream指令上下文

### 问题:

需要在多台 UDP 服务器间实现负载均衡

### 解决方案:

NGINX stream 模块实现 UDP 服务器的负载均衡，作为 UDP 服务器的代理的

upstream 块级指令被定义称使用 UDP 协议: 

```
stream {
 upstream ntp {
 server ntp1.example.com:123 weight=2;
 server ntp2.example.com:123;
 }
 server {
 listen 123 udp;
 proxy_pass ntp;
 }
}
```

示例中，对 2 台使用 UDP 协议的 NTP 服务器进行负载均衡代理。实现 UDP 协议 

的负载均衡，简单到仅需在 server 指令块中的 listen 指令加上一个 udp 

参数就可以了。

### 结论:

或许有人会问 “既然有多条 A 记录或 SRV 记录的 DNS 域名解析，为什么我 

还需要使用 NGINX 的负载均衡功能呢？” 我们的理由是，NGINX 不仅提供了 

多种负载均衡算法，而且还能对 DNS 服务器本身进行负载均衡处理。UDP 协 

议构建了 DNS 解析、NTP 服务器、IP 语音服务等大量基础服务。UDP 负载 

均衡在某些场景下运用不是特别广泛，但在整个网络世界则并非如此。 

UDP 负载均衡同 TCP 负载均衡一样集成在 stream 模块内，并且它们的使用 

方法也几乎一样。二者的主要区别是，在 listen 指令中定义用于 UDP 协议 

的套接字及 udp 参数。此外，还有一些仅用于 UDP 协议的指令，像 

proxy_response 指令，proxy_response 指令告知 NGINX 服务器从被代理服 

务器接收多少预期响应，默认是无限制的，直到达到 proxy_timeout 设定值。 

## 2、负载均衡算法

### 问题:

你需要分配UDP服务的负载，并控制目标或最佳表现。

### 解决方案:

利用不同的负载平衡算法，比如IP散列或least.

```
upstream dns {
 least_conn;
 server ns1.example.com:53;
 server ns2.example.com:53; }
```

配置负载均衡在两个DNS名称服务器和用最少的电流将请求定向到名称服务器

当前连接.

## 3、UDP服务器健康检测

### 问题:

检测 upstream 指令中的 UDP 服务器是否健康。

### 解决方案:

对 UDP 负载均衡配置进行健康检测，确保只对正常运行的 UDP 服务器发送 

数据报文：

```
upstream ntp {
 server ntp1.example.com:123 max_fails=3 fail_timeout=3s;
 server ntp2.example.com:123 max_fails=3 fail_timeout=3s; }
```

配置采用被动检测功能，将 max_fails 指令设置为 3 次，fail_timeout 设置为3秒.

### 结论:

无论何种负载均衡，无论从用户体验角度，还是商业角度，健康检测都至关 

重要。NGINX 同样提供 UDP 负载均衡主动和被动检测方案。被动检测会监测 

连接失败及超时请求作为失效服务判断。主动检测会主动发送数据包值指定 

端口，通过配置的预期响应判断服务是否有效。

# 性能调优

## 1、使用负载测试工具实现自动化测试

### 问题:

使用负载测试工具实现自动化测试

### 解决方案:

使用 HTTP 负载测试工具：如 Apache JMeter/ Locust/ Gatling/或团队 

自研的负载工具。为测试定制测试配置，并对服务器进行全面测试，基于 

测试结果量化性能指标；之后，逐步增加用户数增加并发量，以模拟生产 

环境真实请求，找出性能瓶颈优化；如此反复，直至达到项目的预期性能。 

### 结论:

使用自动化的测试工具来定义您的测试，可以让您通过一个一致的测试来 

找出对 NGINX 进行调优的基准。性能测试必须是可重复的，通过对性能测 

试结果进行科学分析。在对 NGINX 配置进行优化前，需对服务器进行测试 

确定标准，这样，才能确定之后的配置优化是否实现了性能的优化。对每个 

配置优化进行度量，将帮助您确定性能得以提升的根源。

## 2、启用客户端长连接

### 问题:

增加单个连接的请求数，同时增加空闲连接(idle connections)的的连接时长.

### 解决方案:

keepalive_requests 和 keepalive_timeout 指令允许变更单个连接的最大请求数和

空闲连接的连接时长:

```nginx
http {keepalive_requests 320; keepalive_timeout 300s; ... }
```

keepalive_requests 默认为 100，keepalive_timeout 的默认值为 75 秒。

### 结论:

一般情况下，keepalive_requests 和 keepalive_timeout 的默认配置，能够满足 

客户端的请求，因为，现代浏览器能为不同域名打开多个连接。但对于同一个域名 

仅能同时发起 10 以内的请求，这将带来性能瓶颈。CDN 的实现原理是启用多个域 

名指向内容服务器，并以编码的方式指定使用的域名，以使浏览器能够打开更多的 

连接。你会发现使用更多的请求连接数和连接时长配置，在客户端需要频繁更新数 

据能提升服务器性能。 

## 3、启用upstream模块长连接

### 问题:

需要增加代理服务器与被代理服务器的连接数，提升服务器性能。

### 解决方案:

在 upstream 会计指令中使用 keepalive 指令保持代理服务与被代理服务器连接以复用.

```nginx
proxy_http_version 1.1;
proxy_set_header Connection "";
upstream backend {
 server 10.0.0.42;
 server 10.0.2.56;
 
 keepalive 32;
}
```

keepalive 指令会为每个 NGINX worker 进程创建一个连接缓存，表示每个 

worker 进程能保持打开的空闲连接的最大连接数量。如果要使 keepalive 

指令正常工作，在 upstream 指令上使用的 proxy 模块指令则是必须的。 

proxy_http_version 指令表示启用的 http 1.1 版本，它允许在单个连接 

上发送多个请求；proxy_set_header 指令删除 connection 消息头的默认值 

close，这样就允许保持连接的打开状态。 

### 结论:

当需要保持代理服务器与被代理服务器的连接打开状态，以节省启动连接 

所需的时间；同时，需要将 worker 进程收到的请求分发值空闲的连接直接 

处理。有一点需要注意，开启的连接数可以多于 keepalive 配置的连接数， 

因为开启的连接数和空闲连接数不是同一个东西。keepalive 配置的连接数 

应尽量少，以确保新的请求能够被分发到被代理服务器。这条配置技巧能够 

通过减少请求连接的生命周期的手段，提升服务器性能。

## 4、启用响应缓存区

### 问题:

将服务器对客户端的响应写入内存缓冲区而不是文件里。 

### 解决方案:

调整代理模块的缓存区设置，允许 NGINX 服务器将响应消息体写入内存缓冲区： 

```nginx
server {
 proxy_buffering on;
 proxy_buffer_size 8k;
 proxy_buffers 8 32k;
 proxy_busy_buffer_size 64k;
 ...
}
```

proxy_buffering 值可以使 on 或 off，默认是 on。proxy_buffer_size 指令 

表示用于读取来自代理服务器响应的缓冲大小，依据平台不同它的默认值为 

4k 或 8k。proxy_buffers 指令包含两个值，支持的缓存区个数和单个缓存区 

容量大小，默认是 8 个缓存区，依据平台不同单个缓存区默认容量为 4k 或 8k。 

proxy_busy_buffer_size 指令用于配置未完全读取响应时直接响应客户端的缓冲 

区大小，它的空间一般为 proxy_buffers 的两倍为最佳。

### 结论:

代理缓存能显著提升代理服务性能，这取决于响应内容的大小。开启缓冲区设置 

应当仔细测试响应内容的平均大小，并进行大量测试和调试，否则可能引发副作 

用。而如果将缓存区大小设置的非常大也不行，这回占用大量的 NGINX 内存。 

一种方案是将缓冲区大小设置为与最大响应消息相同以提升性能。 

## 5、启用访问日志缓存区

### 问题:

当系统处于负载状态时，启用日志缓冲区以降低 NGINX worker 进程阻塞。 

### 解决方案:

设置 access_log 的 buffer 和 flush 参数： 

```nginx
http {
 access_log /var/log/nginx/access.log main buffer=32k
 flush=1m;
}
```

buffer 参数用于设置，写入文件前的缓冲区内存大小；flush 参数设置缓冲 

区内日志在缓冲区内存中保存的最长时间。 

### 结论:

将日志数据缓冲到内存中可能是很小的一个优化手段。但是，对于有大量请求的 

站点和应用程序的磁盘读写和 CPU 使用性能有重大意义。buffer 参数的功能是 

当缓冲区已经写满时，日志会被写入文件中；flush 参数的功能是，当缓存中的 

日志超过最大缓存时间，也会被写入到文件中，不过也有不足的地方即写入到日 

志文件的日志有些许延迟。